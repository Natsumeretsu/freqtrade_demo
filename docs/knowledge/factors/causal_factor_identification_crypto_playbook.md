# 因果特征识别系统：面向加密择时的工程化落地（本仓库版）

更新日期：2026-01-14

本文目标：把“因果特征识别系统”的关键思想（混淆/碰撞偏差、后门调整、双机器学习、制度依赖、漂移监控）转换为**本仓库可执行、可验证、可迭代**的改进建议与落地路线。

重要前提（务必读）：

- 在量化交易里，我们几乎没有真正的随机对照试验（RCT），“因果”更多是**结构化假设 + 稳健性验证 + 反事实思维**的组合。  
- 因果方法不是魔法：它最擅长解决“**为什么有效**、**什么时候失效**、**控制了哪些偏差**”，而不是保证永远赚钱。
- 本仓库目前依赖较轻（`scikit-learn` + `pandas/numpy`），更适合先做“**因果友好的工程化协议**”，再按需要引入更重的库（DoWhy / econml / lingam）。

原始参考文本（含外链清单）已归档：`docs/knowledge/cache/causal_factor_identification_deep_guide_draft.md`。

配套阅读：

- 工程化基座（因子/门控/训练导出）：`docs/knowledge/freqtrade_qlib_engineering_workflow.md`
- “行业标准”对标（SSOT/一致性/门控/可追溯）：`docs/knowledge/industry_best_practices_support_analysis.md`
- “标准之上的提升空间”（制度/漂移/治理）：`docs/knowledge/industry_best_practices_improvement_space.md`

---

## 1) 把“因果”翻译成工程问题：本仓库最值得补齐的 4 个缺口

### 缺口 A：因子只有“定义”，缺少“机制解释 + 失败模式”

现状：`04_shared/config/factors.yaml` 只描述“要算哪些列”。  
改进目标：对每个核心因子补充最小“因果档案（factor dossier）”：

- 它反映的机制是什么（例如“流动性枯竭”而非“波动率高”）？
- 可能的混淆变量有哪些（例如波动率、成交量、趋势强度）？
- 可能的碰撞变量有哪些（不要乱控）？
- 明显的制度依赖是什么（牛/熊/危机期方向是否翻转）？
- 哪些观测指标可作为“失效预警”（漂移/缺失/极值）？

落地方式（轻量）：

- 先不改 YAML 结构，先在 `docs/knowledge/` 为每个因子集写“机制说明 + 风险清单”，再逐步沉淀到更结构化的元数据文件。

### 缺口 B：训练侧只优化预测指标，缺少“跨制度/跨时间稳定性”视角

现状：`scripts/qlib/train_model.py` 输出验证集指标与权重，但默认只看单一时间切分。  
改进目标：把“因子是否更像因果”转化为可测量的**稳定性**：

- 系数符号是否稳定（多窗口/多折的符号一致性）？
- 重要性是否稳定（Top-K 重合度）？
- 在不同制度桶（趋势/震荡/危机）里的效果是否一致？

落地方式（可在本仓库做）：

- 利用现有 `TimeSeriesSplit` 做多折训练，输出“符号一致率/权重方差”等指标。
- 复用现有门控与因子引擎做制度打标（例如用 `atr_pct`、宏观 SMA、`adx` 的组合）。

### 缺口 C：缺少“混淆控制”的工程化协议（哪怕是近似）

现实：没有实验，只能用观测数据做尽力而为的“后门调整近似”。  
对本仓库的可行版本：

- 用“风险因子集”（例如 `cta_risk`）作为主要混淆控制集合；
- 对候选 alpha 因子做“残差化/正交化”（类似双机器学习的思路），再评估其对目标的边际贡献；
- 把这个过程输出为报告，而不是直接把“因果”当作上线依据。

### 缺口 D：缺少概念漂移/数据质量监控（因子何时失效）

现状：我们更多在“设计时”讨论门控与风险，而不是在“运行时”监控因子/特征是否已经偏离训练分布。  
改进目标：

- 训练时导出特征分布基线（分位数、缺失率、极值比例）
- 回测/实盘时对比当前分布，触发降风险或关机策略

这部分与“制度自适应”是互补关系：制度识别回答“现在是什么市场”，漂移监控回答“我们是否已经走出模型/因子适用域”。

---

## 2) 加密市场下的“因果候选因子”落地建议（不引入外部数据）

你提供的材料强调了 OBV、NATR、成交量、RSI 等在加密市场可能更稳健。  
在本仓库的约束下（在线可计算、只依赖 OHLCV），建议优先补齐：

1) 成交量累积类：OBV（可视为“参与度累积动量”的代理）
2) 波动率归一化类：NATR / ATR%（我们已有 `atr_pct`，可补 `natr` 口径用于对照）
3) 动量/趋势结构：`ema_spread`（已存在）、`ret_n`（已存在）
4) 流动性压力代理：`volume_z_n`、`volume_ratio_n`（已存在）

注意：材料中提到的 MVRV、交易所流入/流出等更偏“链上/交易所资金流”，不在 OHLCV 范围内。  
如果未来要做，需要先设计数据源与缓存策略（建议走采集层/数据层，不要在策略文件里临时拉 API）。

---

## 3) “ADIA 7 步协议”的本仓库轻量化版本（建议）

把复杂协议落地到可复用流程的关键是：每一步都要产出**可追溯产物**。

### 步骤 1：候选因子生成（可配置）

- 输入：`04_shared/config/factors.yaml` 的 factor_sets（例如 `cta_alpha`、`cta_risk`、`cta_core`）
- 输出：候选列清单 + 版本（commit hash / 文件哈希）

### 步骤 2：制度打标（regime labeling）

- 输入：OHLCV + 已有基础因子（`atr_pct`、宏观 SMA、`adx`、`ema_spread`）
- 输出：`regime` 列（离散桶）+ 规则说明（文档固化）

### 步骤 3：混淆控制（后门调整近似）

- 输入：候选因子 X、目标 y、混淆集合 S（建议先用 `cta_risk`）
- 输出：每个 X 的“边际贡献”估计（beta/稳定性/置信度近似）

### 步骤 4：投资规则映射（硬过滤 + 软过滤）

原则：

- 先用硬过滤保护资本（极端波动/流动性不足/制度不匹配时不交易）
- 再用软过滤做连续风险折扣（信号/概率/强度 → 仓位/杠杆）

本仓库已有的落点：

- 硬/软缩放：`03_integration/trading_system/application/risk_scaling.py`
- 入场门控：`03_integration/trading_system/application/entry_gates.py`
- 可观测性：`03_integration/trading_system/application/gate_pipeline.py`

### 步骤 5：压力测试与稳健性（避免“相关性幻觉”）

本仓库已有压力测试脚本（用于把“交易成本/滑点/路径风险”显式化），建议把“因果候选因子/门控”也纳入压力测试评估：

- `scripts/analysis/stress_test.py`

### 步骤 6：多重假设控制（FDR/Bonferroni）

在你同时测试很多因子时，显著性很容易“被随机捡到”。  
本仓库可以先做“工程化替代方案”：

- 用 walk-forward + 制度分桶 + 压力测试作为第一道筛选  
- 真要做统计校正，再引入专门库/实现（不建议一开始就重依赖）

---

## 4) 对本项目的具体改进清单（按优先级）

### P0（建议先做）

1) 给核心因子集补充“机制解释与失败模式”文档（因子档案）  
2) 把“制度分桶评估”加入研究脚本的输出（不仅看整体 AUC）  
3) 增加训练导出中的特征分布基线，为漂移监控铺路

### P1（可选升级）

1) 增加 OBV/NATR/RSI 等 OHLCV 可计算因子（作为候选集，不强塞进默认策略）  
2) 增加“混淆控制近似”的报告脚本（残差化/正交化 + 稳定性输出）  
3) 把漂移信号接入风险折扣（先软后硬）

### P2（长期）

1) 引入 DoWhy/econml/lingam 等重型因果工具链（在研究层，不直接进实盘）  
2) 引入外部数据（链上/资金流/宏观）并设计数据治理与缓存  
3) 策略级动态切换（多策略并行 + 外部调度/元控制器）

